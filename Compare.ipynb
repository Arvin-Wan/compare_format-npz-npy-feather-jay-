{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compare format"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 512, 1001)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "import _pickle as pkl\n",
    "#import cPickle as pkl\n",
    "import os\n",
    "#import tables\n",
    "\n",
    "batch_size = 10\n",
    "embedding_size = 512\n",
    "sample_num = 1000\n",
    "\n",
    "a1 = np.random.normal(size=[embedding_size, sample_num])\n",
    "label = np.random.normal(size=[embedding_size, 1])\n",
    "all_batch = np.concatenate([a1, label], 1)\n",
    
    "\n",
    "all_batches = []\n",
    "for i in range(batch_size):\n",
    "    all_batches.append(all_batch)\n",
    "all_batches = np.array(all_batches)\n",
    "print(all_batches.shape)\n",
    "\n",
    "\n",
    "# dataframe\n",
    "df = pd.DataFrame(all_batch)\n",
    "df1 = pd.DataFrame()\n",
    "for i in range(batch_size):\n",
    "    df1 = pd.concat([df1,df])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pkl dump costs 0.3502919673919678 sec\n",
      "pkl load costs 0.09722304344177246 sec\n",
      "pkl file size: 41001122 byte, 39.10171699523926 mb\n"
     ]
    }
   ],
   "source": [
    "s_t = time.time()\n",
    "pkl_name = \"a.pkl\"\n",
    "with open(pkl_name, \"wb\") as f:\n",
    "    pkl.dump(all_batches, f)\n",
    "pkl_in_time = time.time()-s_t\n",
    "print(\"pkl dump costs {} sec\".format(pkl_in_time))\n",
    "\n",
    "s_t = time.time()\n",
    "with open(pkl_name,'rb') as f:\n",
    "    new_a = pkl.load(f)\n",
    "pkl_out_time = time.time() - s_t\n",
    "print(\"pkl load costs {} sec\".format(pkl_out_time))\n",
    "pkl_size = os.path.getsize(pkl_name)\n",
    "print(\"pkl file size: {} byte, {} mb\".format(pkl_size, float(pkl_size)/(1024*1024)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. npy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "npy save costs 0.036824703216552734 sec\n",
      "npy load costs 0.04144906997680664 sec\n",
      "npy file size: 41001088 byte, 39.1016845703125 mb\n"
     ]
    }
   ],
   "source": [
    "s_t = time.time()\n",
    "npy_name = \"a.npy\"\n",
    "with open(npy_name, \"wb\") as f:\n",
    "    np.save(f, arr=all_batches)\n",
    "npy_in_time = time.time() - s_t\n",
    "print(\"npy save costs {} sec\".format(npy_in_time))\n",
    "\n",
    "s_t = time.time()\n",
    "with open(npy_name,'rb') as f:\n",
    "    new_a = np.load(f)\n",
    "npy_out_time = time.time() - s_t\n",
    "print(\"npy load costs {} sec\".format(npy_out_time))\n",
    "npy_size = os.path.getsize(npy_name)\n",
    "print(\"npy file size: {} byte, {} mb\".format(npy_size, float(npy_size) / (1024*1024)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. npz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "npz save costs 0.3072493076324463 sec\n",
      "npz load costs 0.11807441711425781 sec\n",
      "npz file size: 41001220 byte, 39.101810455322266 mb\n"
     ]
    }
   ],
   "source": [
    "s_t = time.time()\n",
    "npz_name = \"a.npz\"\n",
    "with open(npz_name, \"wb\") as f:\n",
    "    np.savez(f, arr=all_batches)\n",
    "npz_in_time = time.time() - s_t\n",
    "print(\"npz save costs {} sec\".format(npz_in_time))\n",
    "\n",
    "s_t = time.time()\n",
    "with open(npz_name,'rb') as f:\n",
    "    npz_f= np.load(f)\n",
    "    new_a = npz_f[\"arr\"]\n",
    "npz_out_time = time.time() - s_t\n",
    "print(\"npz load costs {} sec\".format(npz_out_time))\n",
    "npz_size = os.path.getsize(npz_name)\n",
    "print(\"npz file size: {} byte, {} mb\".format(npz_size, float(npz_size) /(1024*1024)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. h5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "table save costs 0.2012922763824463 sec\n",
      "table load costs 0.06366372108459473 sec\n",
      "table file size: 41024624 byte, 39.12413024902344 MB\n"
     ]
    }
   ],
   "source": [
    "import tables\n",
    "\n",
    "s_t = time.time()\n",
    "table_name = \"a.h5\"\n",
    "with tables.open_file(table_name,'w') as f:\n",
    "#f = tables.open_file(table_name, 'w')\n",
    "    atom = tables.Atom.from_dtype(all_batches.dtype)\n",
    "    ds = f.create_carray(f.root, 'test_a', atom, all_batches.shape)\n",
    "    ds[:] = all_batches\n",
    "table_in_time = time.time() - s_t\n",
    "print(\"table save costs {} sec\".format(table_in_time))\n",
    "\n",
    "s_t2 = time.time()\n",
    "with tables.open_file(table_name,'r') as f:\n",
    "#f2 = tables.openFile(table_name, \"r\")\n",
    "    hdf5_data = f.root.test_a[:]\n",
    "table_out_time = time.time() - s_t2\n",
    "print(\"table load costs {} sec\".format(table_out_time))\n",
    "table_size = os.path.getsize(table_name)\n",
    "print(\"table file size: {} byte, {} MB\".format(table_size, float(table_size) / (1024*1024)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. feather\n",
    "feather安装：\n",
    "pip install feather-format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "faether write costs 0.2934298515319824 sec\n",
      "faether load costs 0.09006571769714355 sec\n",
      "feather file size: 4650922 byte, 4.435464859008789 MB\n"
     ]
    }
   ],
   "source": [
    "import feather\n",
    "\n",
    "    #df1 = df1.append(pd.DataFrame(all_batch))\n",
    "    #print(df1.shape)\n",
    "s_t = time.time()\n",
    "feather_name = 'a.feather'\n",
    "with open(feather_name,'wb') as f:\n",
    "    feather.write_dataframe(df1,f)\n",
    "feather_in_time = time.time() -s_t\n",
    "print(\"faether write costs {} sec\".format(feather_in_time))\n",
    "\n",
    "s_t2 = time.time()\n",
    "with open(feather_name,'rb') as f:\n",
    "    readFeather = feather.read_dataframe(f)\n",
    "feather_out_time = time.time() -s_t2 \n",
    "\n",
    "print(\"faether load costs {} sec\".format(feather_out_time))\n",
    "feather_size = os.path.getsize(feather_name)\n",
    "print(\"feather file size: {} byte, {} MB\".format(feather_size, float(feather_size) / (1024*1024)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Jay\n",
    "!pip install datatable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type='text/css'>\n",
       ".datatable table.frame { margin-bottom: 0; }\n",
       ".datatable table.frame thead { border-bottom: none; }\n",
       ".datatable table.frame tr.coltypes td {  color: #FFFFFF;  line-height: 6px;  padding: 0 0.5em;}\n",
       ".datatable .bool    { background: #DDDD99; }\n",
       ".datatable .object  { background: #565656; }\n",
       ".datatable .int     { background: #5D9E5D; }\n",
       ".datatable .float   { background: #4040CC; }\n",
       ".datatable .str     { background: #CC4040; }\n",
       ".datatable .time    { background: #40CC40; }\n",
       ".datatable .row_index {  background: var(--jp-border-color3);  border-right: 1px solid var(--jp-border-color0);  color: var(--jp-ui-font-color3);  font-size: 9px;}\n",
       ".datatable .frame tbody td { text-align: left; }\n",
       ".datatable .frame tr.coltypes .row_index {  background: var(--jp-border-color0);}\n",
       ".datatable th:nth-child(2) { padding-left: 12px; }\n",
       ".datatable .hellipsis {  color: var(--jp-cell-editor-border-color);}\n",
       ".datatable .vellipsis {  background: var(--jp-layout-color0);  color: var(--jp-cell-editor-border-color);}\n",
       ".datatable .na {  color: var(--jp-cell-editor-border-color);  font-size: 80%;}\n",
       ".datatable .sp {  opacity: 0.25;}\n",
       ".datatable .footer { font-size: 9px; }\n",
       ".datatable .frame_dimensions {  background: var(--jp-border-color3);  border-top: 1px solid var(--jp-border-color0);  color: var(--jp-ui-font-color3);  display: inline-block;  opacity: 0.6;  padding: 1px 10px 1px 5px;}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "jay write costs 64.61445426940918 sec\n",
      "jay read costs 0.08871698379516602 sec\n",
      "jay file size: 41045088 byte, 39.143646240234375 MB\n"
     ]
    }
   ],
   "source": [
    "import datatable as dt\n",
    "\n",
    "s_t = time.time()\n",
    "jay_name = 'a.jay'\n",
    "dt.Frame(df1).to_jay(jay_name)\n",
    "jay_in_time = time.time() - s_t\n",
    "print(\"jay write costs {} sec\".format(jay_in_time))\n",
    "\n",
    "s_t2= time.time()\n",
    "jay_data =dt.fread(jay_name)\n",
    "jay_out_time = time.time() - s_t2\n",
    "print(\"jay read costs {} sec\".format(jay_out_time))\n",
    "\n",
    "jay_size = os.path.getsize(jay_name)\n",
    "print(\"jay file size: {} byte, {} MB\".format(jay_size, float(jay_size) / (1024*1024)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Parquet\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parquet write costs 0.42542076110839844 sec\n",
      "Parquet read costs 0.20275330543518066 sec\n",
      "Parquet file size: 5662560 byte, 5.400238037109375 MB\n"
     ]
    }
   ],
   "source": [
    "import pyarrow.parquet as pq\n",
    "import pyarrow as pa\n",
    "Parquet_name = 'a.parquet'\n",
    "\n",
    "s_t = time.time()\n",
    "table = pa.Table.from_pandas(df1)\n",
    "pq.write_table(table,Parquet_name)\n",
    "Parquet_in_time = time.time() - s_t\n",
    "print(\"Parquet write costs {} sec\".format(Parquet_in_time))\n",
    "\n",
    "s_t2 = time.time()\n",
    "parquet_data = pd.read_parquet(Parquet_name)\n",
    "Parquet_out_time = time.time() - s_t2\n",
    "print(\"Parquet read costs {} sec\".format(Parquet_out_time))\n",
    "\n",
    "parquet_size = os.path.getsize(Parquet_name)\n",
    "print(\"Parquet file size: {} byte, {} MB\".format(parquet_size, float(parquet_size) / (1024*1024)))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "657381ab66ce38752da39d85da8ddbd9ec305ee1e6ab82a9c32a4aac5a0f8b78"
  },
  "kernelspec": {
   "display_name": "Python 3.6.10 ('ssrnet': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
